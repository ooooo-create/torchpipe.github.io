"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[2012],{3905:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>g});var r=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function p(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var i=r.createContext({}),s=function(e){var t=r.useContext(i),n=t;return e&&(n="function"==typeof e?e(t):p(p({},t),e)),n},u=function(e){var t=s(e.components);return r.createElement(i.Provider,{value:t},e.children)},c="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},m=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,o=e.originalType,i=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),c=s(n),m=a,g=c["".concat(i,".").concat(m)]||c[m]||d[m]||o;return n?r.createElement(g,p(p({ref:t},u),{},{components:n})):r.createElement(g,p({ref:t},u))}));function g(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=n.length,p=new Array(o);p[0]=m;var l={};for(var i in t)hasOwnProperty.call(t,i)&&(l[i]=t[i]);l.originalType=e,l[c]="string"==typeof e?e:a,p[1]=l;for(var s=2;s<o;s++)p[s]=n[s];return r.createElement.apply(null,p)}return r.createElement.apply(null,n)}m.displayName="MDXCreateElement"},4692:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>i,contentTitle:()=>p,default:()=>d,frontMatter:()=>o,metadata:()=>l,toc:()=>s});var r=n(7462),a=(n(7294),n(3905));const o={id:"training",title:"\u8bad\u7ec3\u7684\u96c6\u6210",type:"explainer"},p=void 0,l={unversionedId:"tools/training",id:"tools/training",title:"\u8bad\u7ec3\u7684\u96c6\u6210",description:"\u8fd9\u90e8\u5206\u529f\u80fd\u8fed\u4ee3\u4e2d\u3002",source:"@site/i18n/zh/docusaurus-plugin-content-docs/current/tools/training.md",sourceDirName:"tools",slug:"/tools/training",permalink:"/zh/docs/tools/training",draft:!1,editUrl:"https://g.hz.netease.com/deploy/torchpipe-docs/-/tree/master/website/i18n/zh/docusaurus-plugin-content-docs/current/tools/training.md",tags:[],version:"current",lastUpdatedBy:"zhangshiyang",lastUpdatedAt:1691482040,formattedLastUpdatedAt:"2023\u5e748\u67088\u65e5",frontMatter:{id:"training",title:"\u8bad\u7ec3\u7684\u96c6\u6210",type:"explainer"},sidebar:"main",previous:{title:"\u91cf\u5316",permalink:"/zh/docs/tools/quantization"},next:{title:"\u6d41\u6c34\u7ebf\u8c03\u5ea6\u7cfb\u7edf\u7684\u8c03\u8bd5",permalink:"/zh/docs/tools/debug"}},i={},s=[{value:"Motivation",id:"motivation",level:3},{value:"Major features",id:"major-features",level:3},{value:"Quick Usage",id:"quick-usage",level:3},{value:"step 1: \u51c6\u5907toml",id:"step-1-\u51c6\u5907toml",level:5},{value:"step 2: import library",id:"step-2-import-library",level:5},{value:"step 3: dataset not need augment, and change loader to cv2_loader",id:"step-3-dataset-not-need-augment-and-change-loader-to-cv2_loader",level:5},{value:"step 4: \u8bbe\u7f6e gpu augment , \u8fd9\u91cc\u4e0d\u9700\u8981resize\u64cd\u4f5c\uff0cresize\u5728torchpipe\u7684toml\u91cc\u9762\u8bbe\u7f6e\u4e86\uff0c\u53ea\u8bbe\u7f6e\u5176\u4ed6\u7684\u5c31\u884c\uff0c\u552f\u4e00\u4e0d\u540c\u7684\u662f ToTensor \u53d8\u6210\u4e86\u81ea\u5b9a\u4e49\u7684 TensorToTensor",id:"step-4-\u8bbe\u7f6e-gpu-augment--\u8fd9\u91cc\u4e0d\u9700\u8981resize\u64cd\u4f5cresize\u5728torchpipe\u7684toml\u91cc\u9762\u8bbe\u7f6e\u4e86\u53ea\u8bbe\u7f6e\u5176\u4ed6\u7684\u5c31\u884c\u552f\u4e00\u4e0d\u540c\u7684\u662f-totensor-\u53d8\u6210\u4e86\u81ea\u5b9a\u4e49\u7684-tensortotensor",level:5},{value:"step 5: \u5982\u679c\u8981\u505agpu\u4e0ecpu\u7684\u8054\u5408\u9884\u5904\u7406\uff0c\u9700\u8981\u540c\u65f6\u8bbe\u7f6e cpu augment, \u8fd9\u4e2a\u5c31\u662f\u6b63\u5e38\u6309\u7167pytorch\u539f\u6765\u7684\u5c31\u884c\u3002",id:"step-5-\u5982\u679c\u8981\u505agpu\u4e0ecpu\u7684\u8054\u5408\u9884\u5904\u7406\u9700\u8981\u540c\u65f6\u8bbe\u7f6e-cpu-augment-\u8fd9\u4e2a\u5c31\u662f\u6b63\u5e38\u6309\u7167pytorch\u539f\u6765\u7684\u5c31\u884c",level:5},{value:"step 6: \u5c06dataloader\u7c7b\u8fdb\u884c\u5305\u88c5\uff0c\u5305\u88c5\u6210\u6211\u4eec\u7684wrap_dataloader_torchpipe\u7c7b\u3002",id:"step-6-\u5c06dataloader\u7c7b\u8fdb\u884c\u5305\u88c5\u5305\u88c5\u6210\u6211\u4eec\u7684wrap_dataloader_torchpipe\u7c7b",level:5},{value:"step 7: \u5c06val\u505a\u8ddftrain\u540c\u6837\u7684\u64cd\u4f5c\u3002",id:"step-7-\u5c06val\u505a\u8ddftrain\u540c\u6837\u7684\u64cd\u4f5c",level:5},{value:"step 8: \u6bcf\u4e2aepoch\u9700\u8981\u91cd\u7f6e\u4e00\u4e0b\u8fed\u4ee3\u5668",id:"step-8-\u6bcf\u4e2aepoch\u9700\u8981\u91cd\u7f6e\u4e00\u4e0b\u8fed\u4ee3\u5668",level:5},{value:"\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u5982\u4f55\u8fdb\u884c\u672c\u5730\u6d4b\u8bd5?",id:"\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u5982\u4f55\u8fdb\u884c\u672c\u5730\u6d4b\u8bd5",level:3},{value:"\u65b9\u6848\u4e00\uff08\u63a8\u8350\uff09\uff1a\u89e3\u7801\u548c\u6a21\u578b\u5168\u90e8\u4f7f\u7528torchpipe\u6765\u5b8c\u6210",id:"\u65b9\u6848\u4e00\u63a8\u8350\u89e3\u7801\u548c\u6a21\u578b\u5168\u90e8\u4f7f\u7528torchpipe\u6765\u5b8c\u6210",level:4},{value:"step 1: \u5c06pytorch\u6a21\u578b\u8f6c\u6362\u4e3aonnx\u6a21\u578b\uff0c\u8fd9\u91cc\u53ef\u4ee5\u53c2\u8003\u6587\u6863\uff1apytorch\u6a21\u578b\u8f6connx",id:"step-1-\u5c06pytorch\u6a21\u578b\u8f6c\u6362\u4e3aonnx\u6a21\u578b\u8fd9\u91cc\u53ef\u4ee5\u53c2\u8003\u6587\u6863pytorch\u6a21\u578b\u8f6connx",level:5},{value:"step 2: \u5b9e\u73b0toml",id:"step-2-\u5b9e\u73b0toml",level:5},{value:"step3 \uff1a \u524d\u5411\u7684\u4ee3\u7801",id:"step3--\u524d\u5411\u7684\u4ee3\u7801",level:5},{value:"\u65b9\u6848\u4e8c\uff1a\u53ea\u4f7f\u7528torchpipe\u6765\u5b8c\u6210gpu\u89e3\u7801\u3001resize\uff0c\u6a21\u578b\u4f9d\u7136\u4f7f\u7528PyTorch\u7684\u6a21\u578b",id:"\u65b9\u6848\u4e8c\u53ea\u4f7f\u7528torchpipe\u6765\u5b8c\u6210gpu\u89e3\u7801resize\u6a21\u578b\u4f9d\u7136\u4f7f\u7528pytorch\u7684\u6a21\u578b",level:4},{value:"step1: toml\u4f8b\u5b50(\u5efa\u8bae\u4e0eval\u7684toml\u4fdd\u6301\u4e00\u81f4)",id:"step1-toml\u4f8b\u5b50\u5efa\u8bae\u4e0eval\u7684toml\u4fdd\u6301\u4e00\u81f4",level:5},{value:"step2 : infer\u4ee3\u7801\uff1a",id:"step2--infer\u4ee3\u7801",level:5},{value:"For Users:",id:"for-users",level:3}],u={toc:s},c="wrapper";function d(e){let{components:t,...o}=e;return(0,a.kt)(c,(0,r.Z)({},u,o,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("admonition",{type:"caution"},(0,a.kt)("p",{parentName:"admonition"},"\u8fd9\u90e8\u5206\u529f\u80fd\u8fed\u4ee3\u4e2d\u3002")),(0,a.kt)("p",null,"\u4e3a\u4e86\u5bf9\u9f50\u90e8\u7f72\u548c\u8bad\u7ec3\u7684\u524d\u5904\u7406\u8fc7\u7a0b\uff0c\u5f88\u81ea\u7136\u7684\u60f3\u6cd5\u662f\u5c06torchpipe\u52a0\u5165\u8bad\u7ec3\u6d41\u7a0b\u6d41\u6c34\u7ebf\u3002\u7136\u800c\u8fd9\u5e76\u4e0d\u662f\u5bb9\u6613\u7684\uff0c\u4e3b\u8981\u662f\u56e0\u4e3a\u8fd9\u5c06\u6d89\u53ca\u5230\u591a\u5361\u6570\u636e\u7684\u95ee\u9898\u3002\u4e8b\u5b9e\u4e0a\uff0c\u76ee\u524d\u9c9c\u6709\u5c06torchvision\u7684gpu\u524d\u5904\u7406\u52a0\u5165\u8bad\u7ec3\u6d41\u6c34\u7ebf\u7684\u5b9e\u8df5\u3002\u4e00\u4e2a\u53ef\u4f9b\u53c2\u8003\u7684\u4f8b\u5b50\u662f",(0,a.kt)("a",{parentName:"p",href:"https://kornia.readthedocs.io/en/latest/get-started/training.html"},"kornia\u7684training API"),".\u7136\u800c\u5b83\u662f\u975e\u5e38\u91cd\u7684\uff0c\u91cd\u6784\u4e86\u6574\u4e2a\u6d41\u7a0b\u3002"),(0,a.kt)("h3",{id:"motivation"},"Motivation"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"\u5728\u9879\u76ee\u7684train-infer\u8fed\u4ee3\u4e2d\uff0c\u901a\u5e38\u7684\u505a\u6cd5\u662f\u5728\u8bad\u7ec3\u73af\u8282\u4f7f\u7528Open-CV\u6a21\u5757\u5728CPU\u4e0a\u8fdb\u884c\u6570\u636e\u9884\u5904\u7406\uff1b\u800c\u5728\u4e0a\u7ebf\u73af\u8282\u4e2d\uff0c\u5e0c\u671b\u4f7f\u7528GPU\u8fdb\u884c\u8be5\u64cd\u4f5c\u4ee5\u8fdb\u4e00\u6b65\u63d0\u5347\u4e0a\u7ebf\u670d\u52a1\u6027\u80fd."),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"\u5173\u4e8e\u672c\u9879\u76ee\u5e26\u6765\u7684\u670d\u52a1\u6027\u80fd\u63d0\u5347\u6d4b\u8bd5\uff0c\u53ef\u4ee5\u53c2\u8003\u4e0b\u9762\u7684\u6027\u80fd\u63d0\u5347\u5b9e\u9a8c\uff08QPS\u3001RT\u7b49\u6307\u6807\u53d7\u5b9e\u9645\u7ebf\u4e0a\u73af\u5883\u3001\u6570\u636e\u5f71\u54cd\u8f83\u5927\uff0c\u4ec5\u4f9b\u53c2\u8003\uff09\n",(0,a.kt)("img",{alt:"image",src:n(2713).Z,width:"918",height:"435"}))))),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"\u57fa\u4e8eCPU\u7684\u6570\u636e\u9884\u5904\u7406\u4e0eGPU\u4e0d\u5bf9\u9f50\uff0c\u53ef\u80fd\u4f1a\u5bfc\u81f4\u6a21\u578b\u7684\u8bc6\u522b\u6548\u679c\u51fa\u73b0\u6ce2\u52a8\uff0c\u56e0\u800c\u9650\u5236\u4e86infer\u65f6GPU\u89e3\u7801\u7684\u5e94\u7528\u3002"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"\u5173\u4e8etrain-infer\u4e0d\u5bf9\u9f50\u5e26\u6765\u7684\u8d1f\u9762\u5f71\u54cd\u548c\u672c\u9879\u76ee\u5e26\u6765\u7684\u6539\u8fdb\uff0c\u53ef\u4ee5\u53c2\u8003\u4e0b\u9762\u7684\u6548\u679c\u4e00\u81f4\u6027\u6d4b\u8bd5\u5b9e\u9a8c,\u6548\u679c\u7ed3\u8bba\u53ef\u4ee5\u770b\u8868\u4e2d\u6ce8\u91ca\u90e8\u5206\n",(0,a.kt)("img",{alt:"image",src:n(1896).Z,width:"1034",height:"367"})))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"\u672c\u9879\u76ee\u5e0c\u671b\u5728Pytorch\u8bad\u7ec3\u6846\u67b6\u4e2d\u57fa\u4e8eTorchpipe\u52a0\u901f\u6846\u67b6\u5b9e\u73b0GPU\u9884\u5904\u7406\uff0c\u540c\u65f6\u5229\u7528Torchpipe\u7684\u591a\u5b9e\u4f8b\u64cd\u4f5c\uff0c\u6709\u6548\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u3002"))),(0,a.kt)("h3",{id:"major-features"},"Major features"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"\u5c06Torchpipe\u6846\u67b6\u4f5c\u4e3aGPU\u9884\u5904\u7406pipeline\u5d4c\u5165\u901a\u7528\u7684Pytorch\u8bad\u7ec3\u6846\u67b6\u4e2d\uff0c\u5b9e\u73b0\u4fbf\u6377\u5f0f\u4f7f\u7528"),(0,a.kt)("li",{parentName:"ul"},"Train-Infer\u7684gpu\u89e3\u7801\u5bf9\u9f50\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u4e0a\u7ebf\u670d\u52a1\u6027\u80fd\uff08\u5e76\u53d1\u3001\u8017\u65f6\u7b49\uff09"),(0,a.kt)("li",{parentName:"ul"},"\u5229\u7528\u7ebf\u7a0b\u6c60\u3001\u7f13\u5b58\u961f\u5217\u3001\u591a\u5361\u5206\u53d1\u6570\u636e\u7b49\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u591a\u8fdb\u7a0bDataloader & GPU\u8d1f\u8f7d\u5747\u8861 & \u9ad8\u6548\u8bad\u7ec3"),(0,a.kt)("li",{parentName:"ul"},"\u652f\u6301DP & DDP\u7b49\u591a\u79cd\u5206\u5e03\u5f0f\u8bad\u7ec3\u6a21\u5f0f"),(0,a.kt)("li",{parentName:"ul"},"\u540c\u65f6\u652f\u6301cpu\u4e0egpu\u89e3\u7801\uff0c\u53ef\u901a\u8fc7\u53c2\u6570\u63a7\u5236\u6bd4\u4f8b\uff0c\u53d8\u76f8\u589e\u52a0augment\u64cd\u4f5c")),(0,a.kt)("h3",{id:"quick-usage"},"Quick Usage"),(0,a.kt)("p",null,"\u672c\u6837\u4f8b\u4e2d\uff0c\u63d0\u4f9b\u4e86\u5b66\u4e60\u53c2\u8003\u4ee3\u7801\uff0c\u5728torchpipe\u7684example/gpu_train \u6587\u4ef6\u5939\u4e0b\uff0c\u5206\u522b\u4e3atrain_gpu.py\uff0ctrain_dp.py, train_ddp.py\u3002"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"train_dp.py \u5982\u679c\u591a\u5361\u5e76\u884c\u4f7f\u7528\u4e86dp\uff0c\u53ef\u4ee5\u53c2\u8003\u8fd9\u4efd\u4ee3\u7801\u3002",(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre"},"sh train_dp.sh\n"))),(0,a.kt)("li",{parentName:"ul"},"train_ddp.py \u5982\u679c\u591a\u5361\u5e76\u884c\u4f7f\u7528\u4e86ddp\uff0c\u53ef\u4ee5\u53c2\u8003\u8fd9\u4efd\u4ee3\u7801\u3002",(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre"},"sh train_ddp.sh\n")))),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"\u4e3a\u4e86\u65b9\u4fbf\u5927\u5bb6\u8c03\u7528\uff0c\u53ea\u97008\u6b65\uff0c\u5c31\u53ef\u4ee5\u5c06\u8be5\u65b9\u6cd5\u5e94\u7528\u5230\u60a8\u7684\u9879\u76ee\u4e2d\u53bb\u3002")),(0,a.kt)("h5",{id:"step-1-\u51c6\u5907toml"},"step 1: \u51c6\u5907toml"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"toml\u4e3b\u8981\u7528\u4e8e\u8bbe\u7f6egpu decode\u3001resize\u7b49\u64cd\u4f5c\u3002"),(0,a.kt)("li",{parentName:"ul"},"\u53ef\u4ee5\u53c2\u8003\u4f8b\u5b50\u4e2d\u7684toml\u6587\u4ef6\u5939\u4e0b\u7684gpu_decode_train.toml\u4ee5\u53cagpu_decode_val.toml\uff0c\u5206\u522b\u7528\u4e8etrain\u548cval\u7684\u6570\u636e\u52a0\u8f7d\u4ee5\u53ca\u9884\u5904\u7406\u8fc7\u7a0b\uff0c"),(0,a.kt)("li",{parentName:"ul"},"\u5982\u6709\u5fc5\u8981\uff0c\u53ef\u4ee5\u5728\u5176\u4e2d\u4fee\u6539\u5bf9\u5e94\u7684\u64cd\u4f5c\u3002")),(0,a.kt)("h5",{id:"step-2-import-library"},"step 2: import library"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"from wrap_loader_torchpipe import cv2_loader, DataLoader , TensorToTensor\n")),(0,a.kt)("h5",{id:"step-3-dataset-not-need-augment-and-change-loader-to-cv2_loader"},"step 3: dataset not need augment, and change loader to cv2_loader"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"train_dataset = datasets.ImageFolder(traindir, loader=cv2_loader)\n\n")),(0,a.kt)("h5",{id:"step-4-\u8bbe\u7f6e-gpu-augment--\u8fd9\u91cc\u4e0d\u9700\u8981resize\u64cd\u4f5cresize\u5728torchpipe\u7684toml\u91cc\u9762\u8bbe\u7f6e\u4e86\u53ea\u8bbe\u7f6e\u5176\u4ed6\u7684\u5c31\u884c\u552f\u4e00\u4e0d\u540c\u7684\u662f-totensor-\u53d8\u6210\u4e86\u81ea\u5b9a\u4e49\u7684-tensortotensor"},"step 4: \u8bbe\u7f6e gpu augment , \u8fd9\u91cc\u4e0d\u9700\u8981resize\u64cd\u4f5c\uff0cresize\u5728torchpipe\u7684toml\u91cc\u9762\u8bbe\u7f6e\u4e86\uff0c\u53ea\u8bbe\u7f6e\u5176\u4ed6\u7684\u5c31\u884c\uff0c\u552f\u4e00\u4e0d\u540c\u7684\u662f ","[ToTensor]"," \u53d8\u6210\u4e86\u81ea\u5b9a\u4e49\u7684 ","[TensorToTensor]"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"\ntrain_transform_gpu = transforms.Compose([       \n    transforms.RandomCrop(224),\n    transforms.RandomHorizontalFlip(0.05),\n    transforms.RandomGrayscale(0.02),\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(0.05, 0.05, 0.05),  ## 4\u4e2a\u53c2\u6570\u8fd9\u91cc\u8bbe\u7f6e3\u4e2a\uff0c\u662f\u56e0\u4e3a\u6700\u540e\u7684hue\u53c2\u6570\u57281080Ti\u8ba1\u7b97\u4f1a\u5bfc\u81f4\u901f\u5ea6\u53d8\u6162\uff0c\u5176\u4ed6\u663e\u5361\u4e0d\u4f1a\u6709\u95ee\u9898\n    TensorToTensor(),\n    #the same as normalize range [0,1]\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n")),(0,a.kt)("h5",{id:"step-5-\u5982\u679c\u8981\u505agpu\u4e0ecpu\u7684\u8054\u5408\u9884\u5904\u7406\u9700\u8981\u540c\u65f6\u8bbe\u7f6e-cpu-augment-\u8fd9\u4e2a\u5c31\u662f\u6b63\u5e38\u6309\u7167pytorch\u539f\u6765\u7684\u5c31\u884c"},"step 5: \u5982\u679c\u8981\u505agpu\u4e0ecpu\u7684\u8054\u5408\u9884\u5904\u7406\uff0c\u9700\u8981\u540c\u65f6\u8bbe\u7f6e cpu augment, \u8fd9\u4e2a\u5c31\u662f\u6b63\u5e38\u6309\u7167pytorch\u539f\u6765\u7684\u5c31\u884c\u3002"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"\ntrain_transform_cpu =transforms.Compose([\n        cv2Resize((args.image_size, args.image_size)),\n        transforms.ToPILImage(),\n        transforms.RandomHorizontalFlip(0.05),\n        transforms.RandomGrayscale(0.02),\n        transforms.RandomRotation(5),\n        transforms.ColorJitter(0.05, 0.05, 0.05, 0.05),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n")),(0,a.kt)("h5",{id:"step-6-\u5c06dataloader\u7c7b\u8fdb\u884c\u5305\u88c5\u5305\u88c5\u6210\u6211\u4eec\u7684wrap_dataloader_torchpipe\u7c7b"},"step 6: \u5c06dataloader\u7c7b\u8fdb\u884c\u5305\u88c5\uff0c\u5305\u88c5\u6210\u6211\u4eec\u7684wrap_dataloader_torchpipe\u7c7b\u3002"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u8fd9\u91cc\u9700\u8981\u4f20\u5165toml\u7684\u8def\u5f84"),(0,a.kt)("li",{parentName:"ul"},"local_rank\u4e3a\u4f7f\u7528ddp\u7684\u65f6\u5019\u624d\u4f1a\u7528\u5230\u7684\u53c2\u6570\uff0c\u4e0d\u4f7f\u7528ddp\uff0c\u4e0d\u8bbe\u7f6e\u8fd9\u4e2a\u53c2\u6570\u5373\u53ef\u3002"),(0,a.kt)("li",{parentName:"ul"},"cpu_percentage \u4ee3\u8868\u7684\u662fcpu\u89e3\u7801\u4ee5\u53ca\u9884\u5904\u7406\u7684\u767e\u5206\u6bd4\u3002")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"  \nwrap_train_loader = wrap_dataloader_torchpipe( \n        parallel_type = 'ddp',\n        dataloader = train_loader , \n        toml_path = './toml/gpu_decode_train.toml' , \n        local_rank = local_rank ,\n        transforms_gpu = train_transform_gpu ,\n        transforms_cpu = train_transform_cpu , \n        cpu_percentage = 0.3\n)\n")),(0,a.kt)("h5",{id:"step-7-\u5c06val\u505a\u8ddftrain\u540c\u6837\u7684\u64cd\u4f5c"},"step 7: \u5c06val\u505a\u8ddftrain\u540c\u6837\u7684\u64cd\u4f5c\u3002"),(0,a.kt)("h5",{id:"step-8-\u6bcf\u4e2aepoch\u9700\u8981\u91cd\u7f6e\u4e00\u4e0b\u8fed\u4ee3\u5668"},"step 8: \u6bcf\u4e2aepoch\u9700\u8981\u91cd\u7f6e\u4e00\u4e0b\u8fed\u4ee3\u5668"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"\nwrap_train_loader.reset()\nwrap_val_loader.reset()\n")),(0,a.kt)("h3",{id:"\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u5982\u4f55\u8fdb\u884c\u672c\u5730\u6d4b\u8bd5"},"\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u5982\u4f55\u8fdb\u884c\u672c\u5730\u6d4b\u8bd5?"),(0,a.kt)("p",null,"\u8bad\u7ec3\u548c\u6d4b\u8bd5\u5bc6\u4e0d\u53ef\u5206\uff0c\u524d\u9762\u6211\u4eec\u5df2\u7ecf\u5b9e\u73b0\u4e86\u5229\u7528torchpipe\u5b9e\u73b0gpu\u89e3\u7801\uff0c\u5e76\u5c06\u6a21\u578b\u8bad\u7ec3\u5b8c\u6210\uff0c\u90a3\u4e48\u5982\u4f55\u5229\u7528\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u6765\u8fdb\u884cgpu\u89e3\u7801\u6d4b\u8bd5\u5462\uff1f"),(0,a.kt)("p",null,"\u8fd9\u91cc\u4e3b\u8981\u6d89\u53ca\u4e24\u4e2a\u95ee\u9898\uff1a"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"\u5728\u6d4b\u8bd5\u9636\u6bb5\u5982\u4f55\u5b9e\u73b0gpu\u89e3\u7801\u4e0e\u9884\u5904\u7406\u3002"),(0,a.kt)("li",{parentName:"ol"},"\u6a21\u578b\u5982\u4f55\u8fdb\u884c\u524d\u5411\u3002")),(0,a.kt)("p",null,"\u8fd9\u91cc\u7ed9\u51fa\u4e24\u79cd\u89e3\u51b3\u65b9\u6848\uff0c\u4f9b\u5927\u5bb6\u53c2\u8003\uff0c\u53ef\u6839\u636e\u9879\u76ee\u5b9e\u9645\u60c5\u51b5\u6765\u9009\u62e9\u5177\u4f53\u65b9\u6848\u3002"),(0,a.kt)("p",null,"\u8be6\u7ec6\u4ee3\u7801\u53ef\u4ee5\u53c2\u8003example\u91cc\u9762\u7684test_gpu.py\uff0c\u4ee5\u53catest_gpu.sh\uff0c\u5927\u5bb6\u53ef\u4ee5\u5148\u770b\u4e0b\u9762\u7684\u4ecb\u7ecd\uff0c\u7136\u540e\u518d\u770b\u8be6\u7ec6\u4ee3\u7801\uff0c\u5c31\u4e00\u76ee\u4e86\u7136\u4e86\u3002"),(0,a.kt)("h4",{id:"\u65b9\u6848\u4e00\u63a8\u8350\u89e3\u7801\u548c\u6a21\u578b\u5168\u90e8\u4f7f\u7528torchpipe\u6765\u5b8c\u6210"},"\u65b9\u6848\u4e00\uff08\u63a8\u8350\uff09\uff1a\u89e3\u7801\u548c\u6a21\u578b\u5168\u90e8\u4f7f\u7528torchpipe\u6765\u5b8c\u6210"),(0,a.kt)("p",null,"\u8fd9\u4e2a\u65b9\u6848\u9002\u5408\u9879\u76ee\u76f8\u5bf9\u7b80\u5355\uff08\u6bd4\u5982\u53ea\u67091\u30012\u4e2a\u6a21\u578b\uff09\uff0c\u6216\u8005\u5bf9torchpipe\u5177\u6709\u4e00\u5b9a\u638c\u63e1\uff0c\u53ef\u4ee5\u5229\u7528torchpipe\u5b9e\u73b0\u590d\u6742\u903b\u8f91\u7684\u540c\u5b66"),(0,a.kt)("h5",{id:"step-1-\u5c06pytorch\u6a21\u578b\u8f6c\u6362\u4e3aonnx\u6a21\u578b\u8fd9\u91cc\u53ef\u4ee5\u53c2\u8003\u6587\u6863pytorch\u6a21\u578b\u8f6connx"},"step 1: \u5c06pytorch\u6a21\u578b\u8f6c\u6362\u4e3aonnx\u6a21\u578b\uff0c\u8fd9\u91cc\u53ef\u4ee5\u53c2\u8003\u6587\u6863\uff1a",(0,a.kt)("a",{parentName:"h5",href:"../faq/onnx?_highlight=onnx"},"pytorch\u6a21\u578b\u8f6connx")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"\u8fd9\u4e00\u6b65\u9700\u8981\u6ce8\u610f\u7684\u662f\uff1a\u8981\u4e0d\u8981\u5c06",(0,a.kt)("strong",{parentName:"li"},"\u51cf\u5747\u503c\u3001\u9664\u65b9\u5dee"),"\u653e\u5230\u6a21\u578b\u4e2d\uff0c\u8fd9\u91cc\u505a\u4e86\uff0c\u540e\u9762\u5c31\u4e0d\u9700\u8981\u8fd9\u4e2a\u9884\u5904\u7406\u4e86\u3002")),(0,a.kt)("h5",{id:"step-2-\u5b9e\u73b0toml"},"step 2: \u5b9e\u73b0toml"),(0,a.kt)("p",null,"\u8fd9\u91cc\u7ed9\u4e00\u4e2a\u7b80\u5355\u7684\u901a\u7528\u7248\u672c\uff1a"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"\u8fd9\u4e2a\u7248\u672c\u5b9e\u73b0\u4e86\u89e3\u7801\u4e0e\u6a21\u578b\u524d\u5411\u7684\u57fa\u672c\u64cd\u4f5c\uff0c\u5148\u5bf9\u56fe\u50cf\u8fdb\u884c\u89e3\u7801\u3001resize\u3001cvtcolor\uff0c\u7136\u540e\u8fc7\u6a21\u578b\uff0c\u7ed9\u51fa\u7ed3\u679c\u3002")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'batching_timeout = 1 \ninstance_num =1\n\n[jpg_decoder]\nbackend = "SyncTensor[ Sequential[DecodeTensor,ResizeTensor,cvtColorTensor] ]" \nresize_h = 224\nresize_w = 224 \ncolor = "rgb"\nnext = "cpu_decoder"\ninstance_num =6\n\n[cpu_decoder]\nbackend = "SyncTensor[Sequential[DecodeMat,ResizeMat,cvtColorMat,Mat2Tensor]   ]" \nfilter = "or" \nresize_h = 224 \nresize_w = 224 \ncolor = "rgb"\ninstance_num =8 \nnext = "resnet50"\n\n[resnet50]\nbackend = "SyncTensor[TensorrtTensor]" \nmax=\'4\'\nmodel = "/app/pth/dog-cat/checkpoint_resnet50.onnx"\ninstance_num = 2\n')),(0,a.kt)("h5",{id:"step3--\u524d\u5411\u7684\u4ee3\u7801"},"step3 \uff1a \u524d\u5411\u7684\u4ee3\u7801"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"def init_decodeNode(self):\n    config = torchpipe.parse_toml(self.toml_path)\n    for key in config.keys():\n        if key != 'global':\n            # \u5982\u679ctoml\u91cc\u6ca1\u6709\u6307\u5b9agpu\uff0c\u8fd9\u91cc\u9700\u8981\u6307\u5b9agpu\n            config[key][\"device_id\"] = 0\n    print(config)\n    decode_node = torchpipe.pipe(config)\n    return decode_node\n\n\ndef predict(self, img_path):\n    try:\n        img = open(img_path, 'rb').read()\n        if img is None or img == b'':\n            print('open error:{}'.format(img_path))\n            return None\n        \n        pipe_input = {TASK_DATA_KEY: img, \"node_name\": \"jpg_decoder\"}\n        self.decode_node(pipe_input)\n        result = pipe_input[TASK_RESULT_KEY]\n        result = torch.nn.functional.softmax(result).cpu().numpy()\n        return result\n    \n    except Exception as e:\n        print('error:{}'.format(e))\n        return None\n\n")),(0,a.kt)("h4",{id:"\u65b9\u6848\u4e8c\u53ea\u4f7f\u7528torchpipe\u6765\u5b8c\u6210gpu\u89e3\u7801resize\u6a21\u578b\u4f9d\u7136\u4f7f\u7528pytorch\u7684\u6a21\u578b"},"\u65b9\u6848\u4e8c\uff1a\u53ea\u4f7f\u7528torchpipe\u6765\u5b8c\u6210gpu\u89e3\u7801\u3001resize\uff0c\u6a21\u578b\u4f9d\u7136\u4f7f\u7528PyTorch\u7684\u6a21\u578b"),(0,a.kt)("p",null,"\u8fd9\u4e2a\u65b9\u6cd5\uff0c\u53ea\u9700\u8981\u628a\u539f\u6765PyTorch\u4ee3\u7801\u4e2d\u7684\u9884\u5904\u7406\u4fee\u6539\u4e86\u5c31\u53ef\u4ee5\u4e86\uff0c\u5176\u4ed6\u4e0d\u9700\u8981\u505a\u4fee\u6539\uff0c\u4e5f\u4e0d\u9700\u8981\u8f6connx\u8fd9\u6b65\u9aa4\u4e86\u3002"),(0,a.kt)("h5",{id:"step1-toml\u4f8b\u5b50\u5efa\u8bae\u4e0eval\u7684toml\u4fdd\u6301\u4e00\u81f4"},"step1: toml\u4f8b\u5b50(\u5efa\u8bae\u4e0eval\u7684toml\u4fdd\u6301\u4e00\u81f4)"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"\u5b8c\u6210gpu\u89e3\u7801\u3001resize\u3001cvtColor\u529f\u80fd"),(0,a.kt)("li",{parentName:"ul"},"\u8fd4\u56detensor\u7c7b\u578b(shape:1x3x224x224)")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'batching_timeout = 1 \ninstance_num =1\n\n[jpg_decoder]\nbackend = "SyncTensor[ Sequential[DecodeTensor,ResizeTensor,cvtColorTensor] ]" \nresize_h = 224\nresize_w = 224 \ncolor = "rgb"\nnext = "cpu_decoder"\ninstance_num =6\n\n[cpu_decoder]\nbackend = "SyncTensor[Sequential[DecodeMat,ResizeMat,cvtColorMat,Mat2Tensor]   ]" \nfilter = "or" \nresize_h = 224 \nresize_w = 224 \ncolor = "rgb"\ninstance_num =8 \n\n')),(0,a.kt)("h5",{id:"step2--infer\u4ee3\u7801"},"step2 : infer\u4ee3\u7801\uff1a"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"\ndef init_decodeNode(self):\n    config = torchpipe.parse_toml(self.toml_path)\n    for key in config.keys():\n        if key != 'global':\n            # \u5982\u679ctoml\u91cc\u6ca1\u6709\u6307\u5b9agpu\uff0c\u8fd9\u91cc\u9700\u8981\u6307\u5b9agpu\n            config[key][\"device_id\"] = 0\n    print(config)\n    decode_node = torchpipe.pipe(config)\n    return decode_node\n\n\nmean = [0.485 * 255 , 0.456 * 255, 0.406 * 255]\nstd  = [0.229 * 255 , 0.224 * 255, 0.225 * 255]\n\ndef predict(self, img_path):\n   \n\n    try:\n        img = open(img_path, 'rb').read()\n        if img is None or img == b'':\n            print('open error:{}'.format(img_path))\n            return None\n        \n        pipe_input = {TASK_DATA_KEY: img, \"node_name\": \"jpg_decoder\"}\n        self.decode_node(pipe_input)\n        img_data = pipe_input[TASK_RESULT_KEY]\n        mean_tensor = torch.tensor(mean).unsqueeze(0).unsqueeze(2).unsqueeze(3).repeat(1, 1, 224, 224).cuda() \n        std_tensor = torch.tensor(std).unsqueeze(0).unsqueeze(2).unsqueeze(3).repeat(1, 1, 224, 224).cuda()\n        img_data -= mean_tensor\n        img_data /= std_tensor\n        \n        \n        with torch.no_grad():\n            probs = self.model(img_data)\n            result = torch.nn.functional.softmax(probs).cpu().numpy()\n        return result\n    \n    except Exception as e:\n        print('error:{}'.format(e))\n        return None\n\n\n")),(0,a.kt)("h3",{id:"for-users"},"For Users:"),(0,a.kt)("p",null,"\u672c\u9879\u76ee\u7684\u6838\u5fc3\u5b9e\u73b0\u4ee3\u7801\u4e3b\u8981\u662fgpu_train_tools.py\u4e2d\u57fa\u4e8ePytoch\u8fdb\u4e00\u6b65\u5c01\u88c5\u7684DataLoader\u7c7b\uff0c\u5982\u679c\u60a8\u60f3\u5728\u81ea\u5df1\u5df2\u6709\u7684\u8bad\u7ec3\u6846\u67b6\u4e2d\u6dfb\u52a0\u529f\u80fd\uff0c\u6216\u662f\u8fdb\u4e00\u6b65\u63a2\u7d22\uff0c\u53ef\u4ee5\u53c2\u8003\u8fd9\u4e2a\u7c7b\u8fdb\u884c\u4fee\u6539\u3002"),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"\u5728\u529f\u80fd\u5b9e\u73b0\u8fc7\u7a0b\u4e2d\uff0c\u96be\u514d\u4f1a\u6709\u4e00\u4e9b\u6ca1\u6709\u8003\u8651\u5230\u7684\u5730\u65b9\uff0c\u5982\u679c\u9047\u5230\u4e86bug\uff0c\u8bf7\u8054\u7cfbAuthor(WangLichun\uff0cLinYuxing\uff0cZhangShiyang)\u534f\u52a9\u89e3\u51b3")))}d.isMDXComponent=!0},1896:(e,t,n)=>{n.d(t,{Z:()=>r});const r=n.p+"assets/images/gpu_decode_exp_show_readme-a2efdc3c795ca6d0d5334223d5832721.jpg"},2713:(e,t,n)=>{n.d(t,{Z:()=>r});const r=n.p+"assets/images/gpu_decode_exp_show_readme_2-f163f1aa78bf9ea23483d3bae1f9fb06.jpg"}}]);