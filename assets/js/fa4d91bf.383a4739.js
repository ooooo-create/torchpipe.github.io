"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[5930],{3905:(e,t,n)=>{n.d(t,{Zo:()=>c,kt:()=>h});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var s=a.createContext({}),p=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},c=function(e){var t=p(e.components);return a.createElement(s.Provider,{value:t},e.children)},u="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,s=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),u=p(n),m=r,h=u["".concat(s,".").concat(m)]||u[m]||d[m]||o;return n?a.createElement(h,i(i({ref:t},c),{},{components:n})):a.createElement(h,i({ref:t},c))}));function h(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,i=new Array(o);i[0]=m;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[u]="string"==typeof e?e:r,i[1]=l;for(var p=2;p<o;p++)i[p]=n[p];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},5162:(e,t,n)=>{n.d(t,{Z:()=>i});var a=n(7294),r=n(6010);const o={tabItem:"tabItem_Ymn6"};function i(e){let{children:t,hidden:n,className:i}=e;return a.createElement("div",{role:"tabpanel",className:(0,r.Z)(o.tabItem,i),hidden:n},t)}},4866:(e,t,n)=>{n.d(t,{Z:()=>v});var a=n(7462),r=n(7294),o=n(6010),i=n(2466),l=n(6775),s=n(1980),p=n(7392),c=n(12);function u(e){return function(e){return r.Children.map(e,(e=>{if(!e||(0,r.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}(e).map((e=>{let{props:{value:t,label:n,attributes:a,default:r}}=e;return{value:t,label:n,attributes:a,default:r}}))}function d(e){const{values:t,children:n}=e;return(0,r.useMemo)((()=>{const e=t??u(n);return function(e){const t=(0,p.l)(e,((e,t)=>e.value===t.value));if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[t,n])}function m(e){let{value:t,tabValues:n}=e;return n.some((e=>e.value===t))}function h(e){let{queryString:t=!1,groupId:n}=e;const a=(0,l.k6)(),o=function(e){let{queryString:t=!1,groupId:n}=e;if("string"==typeof t)return t;if(!1===t)return null;if(!0===t&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:t,groupId:n});return[(0,s._X)(o),(0,r.useCallback)((e=>{if(!o)return;const t=new URLSearchParams(a.location.search);t.set(o,e),a.replace({...a.location,search:t.toString()})}),[o,a])]}function g(e){const{defaultValue:t,queryString:n=!1,groupId:a}=e,o=d(e),[i,l]=(0,r.useState)((()=>function(e){let{defaultValue:t,tabValues:n}=e;if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(t){if(!m({value:t,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${t}" but none of its children has the corresponding value. Available values are: ${n.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return t}const a=n.find((e=>e.default))??n[0];if(!a)throw new Error("Unexpected error: 0 tabValues");return a.value}({defaultValue:t,tabValues:o}))),[s,p]=h({queryString:n,groupId:a}),[u,g]=function(e){let{groupId:t}=e;const n=function(e){return e?`docusaurus.tab.${e}`:null}(t),[a,o]=(0,c.Nk)(n);return[a,(0,r.useCallback)((e=>{n&&o.set(e)}),[n,o])]}({groupId:a}),b=(()=>{const e=s??u;return m({value:e,tabValues:o})?e:null})();(0,r.useLayoutEffect)((()=>{b&&l(b)}),[b]);return{selectedValue:i,selectValue:(0,r.useCallback)((e=>{if(!m({value:e,tabValues:o}))throw new Error(`Can't select invalid tab value=${e}`);l(e),p(e),g(e)}),[p,g,o]),tabValues:o}}var b=n(2389);const k={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};function f(e){let{className:t,block:n,selectedValue:l,selectValue:s,tabValues:p}=e;const c=[],{blockElementScrollPositionUntilNextRender:u}=(0,i.o5)(),d=e=>{const t=e.currentTarget,n=c.indexOf(t),a=p[n].value;a!==l&&(u(t),s(a))},m=e=>{let t=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{const n=c.indexOf(e.currentTarget)+1;t=c[n]??c[0];break}case"ArrowLeft":{const n=c.indexOf(e.currentTarget)-1;t=c[n]??c[c.length-1];break}}t?.focus()};return r.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,o.Z)("tabs",{"tabs--block":n},t)},p.map((e=>{let{value:t,label:n,attributes:i}=e;return r.createElement("li",(0,a.Z)({role:"tab",tabIndex:l===t?0:-1,"aria-selected":l===t,key:t,ref:e=>c.push(e),onKeyDown:m,onClick:d},i,{className:(0,o.Z)("tabs__item",k.tabItem,i?.className,{"tabs__item--active":l===t})}),n??t)})))}function y(e){let{lazy:t,children:n,selectedValue:a}=e;const o=(Array.isArray(n)?n:[n]).filter(Boolean);if(t){const e=o.find((e=>e.props.value===a));return e?(0,r.cloneElement)(e,{className:"margin-top--md"}):null}return r.createElement("div",{className:"margin-top--md"},o.map(((e,t)=>(0,r.cloneElement)(e,{key:t,hidden:e.props.value!==a}))))}function N(e){const t=g(e);return r.createElement("div",{className:(0,o.Z)("tabs-container",k.tabList)},r.createElement(f,(0,a.Z)({},e,t)),r.createElement(y,(0,a.Z)({},e,t)))}function v(e){const t=(0,b.Z)();return r.createElement(N,(0,a.Z)({key:String(t)},e))}},694:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>s,default:()=>h,frontMatter:()=>l,metadata:()=>p,toc:()=>u});var a=n(7462),r=(n(7294),n(3905)),o=n(4866),i=n(5162);const l={id:"installation",title:"Installation",type:"explainer"},s="Installation",p={unversionedId:"installation",id:"installation",title:"Installation",description:"Using NGC base image",source:"@site/docs/installation.mdx",sourceDirName:".",slug:"/installation",permalink:"/docs/installation",draft:!1,editUrl:"https://g.hz.netease.com/deploy/torchpipe-docs/-/tree/master/website/docs/installation.mdx",tags:[],version:"current",lastUpdatedBy:"zhangshiyang",lastUpdatedAt:1691479968,formattedLastUpdatedAt:"Aug 8, 2023",frontMatter:{id:"installation",title:"Installation",type:"explainer"},sidebar:"main",previous:{title:"\u5feb\u901f\u4e0a\u624b",permalink:"/docs/"},next:{title:"\u521d\u9636\u7248--\u5c0f\u8bd5\u725b\u5200",permalink:"/docs/quick_start_new_user"}},c={},u=[{value:"Using NGC base image",id:"using-ngc-base-image",level:2},{value:"Customizing Dockerfile",id:"selfdocker",level:2},{value:"Description",id:"description",level:2},{value:"Compilation Options",id:"compilation-options",level:3},{value:"Dependencies",id:"dependencies",level:2},{value:"ABI",id:"abi",level:3},{value:"Compiling with integrated third-party libraries (using Ubuntu-OpenCV as an example)",id:"compiling-with-integrated-third-party-libraries-using-ubuntu-opencv-as-an-example",level:3}],d={toc:u},m="wrapper";function h(e){let{components:t,...n}=e;return(0,r.kt)(m,(0,a.Z)({},d,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"installation"},"Installation"),(0,r.kt)("h2",{id:"using-ngc-base-image"},"Using NGC base image"),(0,r.kt)("p",null,"The easiest way is to choose NGC mirror for source code compilation (official mirror may still be able to run low version drivers through Forward Compatibility or Minor Version Compatibility).\nFirst, clone the code:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"git clone -b master ssh://git@g.hz.netease.com:22222/deploy/torchpipe.git\n# git clone -b master https://g.hz.netease.com/deploy/torchpipe.git\ncd torchpipe/ && git submodule update --init --recursive\n")),(0,r.kt)("p",null,"Then start the container and if your machine supports ",(0,r.kt)("a",{parentName:"p",href:"https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch/tags"},"a higher version of the image"),", you can use the updated version of the Pytorch image."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"img_name=nvcr.io/nvidia/pytorch:22.12-py3 #  for cuda11\n# img_name=nvcr.io/nvidia/pytorch:23.05-py3 #  for tensort8.6.1, LayerNorm\ndocker run --rm --gpus=all  --network=host   --ulimit memlock=-1 --ulimit stack=67108864 -v `pwd`:/workspace  --privileged=true -it $img_name /bin/bash\n")),(0,r.kt)("admonition",{type:"note"},(0,r.kt)("p",{parentName:"admonition"},"If you are using a transformer-like model, it is strongly recommended to use TensorRT >= 8.6.1 (",(0,r.kt)("inlineCode",{parentName:"p"},"nvcr.io/nvidia/pytorch:23.05-py3"),") for supporting opset 17 for LayerNormalization and opset 18 GroupNormalization, as well as deeper support for such models. However, the NGC image has certain requirements for the GPU driver version ",(0,r.kt)("a",{parentName:"p",href:"https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/rel-23-05.html#rel-23-05"},"as mentioned here"),":"),(0,r.kt)("pre",{parentName:"admonition"},(0,r.kt)("code",{parentName:"pre"},"*Release 23.05 is based on CUDA 12.1.1, which requires NVIDIA Driver release 530 or later. However, if you are running on a data center GPU (for example, T4 or any other data center GPU), you can use NVIDIA driver release 450.51 (or later R450), 470.57 (or later R470), 510.47 (or later R510), 515.65 (or later R515), 525.85 (or later R525), or 530.30 (or later R530)*\n")),(0,r.kt)("p",{parentName:"admonition"},"This can be overcome by:"),(0,r.kt)("ul",{parentName:"admonition"},(0,r.kt)("li",{parentName:"ul"},"Using the custom image described in the ",(0,r.kt)("a",{parentName:"li",href:"#selfdocker"},"next section")),(0,r.kt)("li",{parentName:"ul"},"For online deployment, only considering support for data center cards such as Tesla T4 for the time being."))),(0,r.kt)("p",null,"Next, you can compile the source code:"),(0,r.kt)(o.Z,{groupId:"pip",className:"unique-tabs",mdxType:"Tabs"},(0,r.kt)(i.Z,{value:"sys",label:"Install to System",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"python setup.py install\n"))),(0,r.kt)(i.Z,{value:"editable",label:"Editable Mode",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"pip install -e .\n"))),(0,r.kt)(i.Z,{value:"whl",label:"Packaging",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"python setup.py bdist_wheel\n# The generated .whl file can be used in different containers of the same image\npip install --upgrade dist/*.whl\n")))),(0,r.kt)("p",null,"Then you can run all the example code:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"cd examples/resnet18 && python resnet18.py\n# or \ncd examples/yolox && python yolox.py \n")),(0,r.kt)("details",null,(0,r.kt)("summary",null,"Parallel inference of resnet18."),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"Obtain the appropriate model file (currently supporting ONNX, TRT engine, etc.).")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'import torchvision.models as models\nresnet18 = models.resnet18(pretrained=True).eval().cuda()\n\nimport tempfile, os, torch\nmodel_path =  os.path.join(tempfile.gettempdir(), "./resnet18.onnx") \nresnet18 = models.resnet18(pretrained=True).eval().cuda()\ndata_bchw = torch.rand((1, 3, 224, 224)).cuda()\nprint("export: ", model_path)\ntorch.onnx.export(resnet18, data_bchw, model_path,\n                  opset_version=17,\n                  do_constant_folding=True,\n                  input_names=["in"], output_names=["out"],dynamic_axes={"in": {0: "x"},"out": {0: "x"}})\n\n# os.system(f"onnxsim {model_path} {model_path}")\n')),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"Now you can make concurrent calls to a single model.")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"import torch, torchpipe\nmodel = torchpipe.pipe({'model': model_path,\n                        'backend': \"Sequential[cvtColorTensor,TensorrtTensor,SyncTensor]\", # Back-end engine, as explained in the \"Overview\" section.\n                        'instance_num': 2, 'batching_timeout': '5', # Number of instances and timeout duration.\n                        'max': 4, # Maximum value for model optimization scope, can also be '4x3x224x224'.\n                        'mean': '123.675, 116.28, 103.53',#255*\"0.485, 0.456, 0.406\"\uff0c\n                        'std': '58.395, 57.120, 57.375', # Merge into TensorRT network.\n                        'color': 'rgb'}) # cvtColorTensor backend parameter: target color space order\ndata = torch.zeros((1, 3, 224, 224)) # or torch.from_numpy(...)\ninput = {\"data\": data, 'color': 'bgr'}\nmodel(input)  # Concurrency can be utilized\n# Use \"result\" as the data output identifier, although other key values can be customized as well.\nprint(input[\"result\"].shape)  # If the inference fails, the \"result\" key will not exist, even if it was present in the input.\n"))),(0,r.kt)("p",null,"For more examples, see ",(0,r.kt)("a",{parentName:"p",href:"/docs/showcase"},"Showcase"),"."),(0,r.kt)("h2",{id:"selfdocker"},"Customizing Dockerfile"),(0,r.kt)("admonition",{type:"tip"},(0,r.kt)("p",{parentName:"admonition"},"If you are within the Netease intranet, you can use the pre-compiled image (Pascal driver >= 510):"),(0,r.kt)("pre",{parentName:"admonition"},(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"docker pull hub.c.163.com/neteaseis/ai/torchpipe:base_trt-8.6\n"))),(0,r.kt)("p",null,"Refer to the ",(0,r.kt)("a",{parentName:"p",href:"https://g.hz.netease.com/deploy/torchpipe/-/blob/master/docker/torchpipe.base"},"example Dockerfile"),". After downloading TensorRT and OpenCV in advance, you can compile the corresponding base image."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"# put TensorRT-8.6.1.6.Linux.x86_64-gnu.cuda-11.8.tar.gz into thirdparty/\nwget https://codeload.github.com/opencv/opencv/zip/refs/tags/4.5.4 -O thirdparty/opencv-4.5.4.zip\n# docker build --network=host -f docker/torchpipe.base -t hub.c.163.com/neteaseis/ai/torchpipe:base_trt-8.6 .\n\n# docker run --rm   --network=host --gpus=all --ulimit memlock=-1 --ulimit stack=67108864 --privileged=true  -v `pwd`:/workspace -it hub.c.163.com/neteaseis/ai/torchpipe:base_trt-8.6  /bin/bash \n\n")),(0,r.kt)("p",null,"Base images compiled in this way have smaller sizes than NGC PyTorch images. Please note that ",(0,r.kt)("inlineCode",{parentName:"p"},"_GLIBCXX_USE_CXX11_ABI==0"),"."),(0,r.kt)("h2",{id:"description"},"Description"),(0,r.kt)("h3",{id:"compilation-options"},"Compilation Options"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Option"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Default"),(0,r.kt)("th",{parentName:"tr",align:"center"},"Description"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEBUG"),(0,r.kt)("td",{parentName:"tr",align:"center"},"0"),(0,r.kt)("td",{parentName:"tr",align:"center"},"Whether to compile in debug mode")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"WITH_OPENCV"),(0,r.kt)("td",{parentName:"tr",align:"center"},"1"),(0,r.kt)("td",{parentName:"tr",align:"center"},"Whether to compile the C++ backend that depends on OpenCV")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"WITH_TENSORRT"),(0,r.kt)("td",{parentName:"tr",align:"center"},"1"),(0,r.kt)("td",{parentName:"tr",align:"center"},"Whether to compile the C++ backend that depends on TensorRT")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"IPIPE_KEY(optinal)"),(0,r.kt)("td",{parentName:"tr",align:"center"},"None"),(0,r.kt)("td",{parentName:"tr",align:"center"},"str(length>=8). If using encryption and decryption functions, this key needs to be set.")))),(0,r.kt)("h2",{id:"dependencies"},"Dependencies"),(0,r.kt)("p",null,"The basic environment is as follows:"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Dependency"),(0,r.kt)("th",{parentName:"tr",align:"left"},"Version"),(0,r.kt)("th",{parentName:"tr",align:null},"Remarks"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"cuda")),(0,r.kt)("td",{parentName:"tr",align:"left"},">= 11.0"),(0,r.kt)("td",{parentName:"tr",align:null},"- The CUDA version must be consistent with the version that PyTorch depends on (for the convenience of ",(0,r.kt)("inlineCode",{parentName:"td"},"torch.utils.cpp_extension")," to compile code on the fly). ",(0,r.kt)("br",null),"- Compatibility testing with CUDA 10.2 is no longer performed.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"pytorch")),(0,r.kt)("td",{parentName:"tr",align:"left"},">= 1.13.0"),(0,r.kt)("td",{parentName:"tr",align:null},"- Compatibility testing is no longer performed for ",(0,r.kt)("inlineCode",{parentName:"td"},"c++14/cuda-10.2/pytorch==1.10.2"),", but you may still be able to run it with simple modifications.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"opencv"),"(optional)"),(0,r.kt)("td",{parentName:"tr",align:"left"},"3.x, 4.x"),(0,r.kt)("td",{parentName:"tr",align:null},"At least the core, imgproc, imgcodecs, and highgui modules are included.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"tensorrt"),"(optional)"),(0,r.kt)("td",{parentName:"tr",align:"left"},">= 7.2",(0,r.kt)("br",null),"<= 8.6.1.5"),(0,r.kt)("td",{parentName:"tr",align:null},"- There is a ",(0,r.kt)("a",{parentName:"td",href:"https://github.com/NVIDIA/TensorRT/issues/351"},"memory leak")," in TensorRT 7.0 with dynamic inputs.",(0,r.kt)("br",null),"- TensorRT 7.1 and earlier cannot directly INT8-quantize models with dynamic inputs.")))),(0,r.kt)("admonition",{type:"note"},(0,r.kt)("p",{parentName:"admonition"},"All dependencies mentioned above come from a specific default backend. The construction of C++ core does not rely on any of the above dependencies.")),(0,r.kt)("h3",{id:"abi"},"ABI"),(0,r.kt)("p",null,"The compiler used for both compiling the code and the dependent libraries needs to be ABI-compatible with the compiler used by the installed PyTorch. In PyTorch, you can check the compatibility as follows:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'python -c "import torch; print(torch._C._GLIBCXX_USE_CXX11_ABI)"\n')),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"left"},"Installation Source"),(0,r.kt)("th",{parentName:"tr",align:"center"},"_GLIBCXX_USE_CXX11_ABI"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("a",{parentName:"td",href:"https://pytorch.org/get-started/locally/"},"PyPI-PyTorch")),(0,r.kt)("td",{parentName:"tr",align:"center"},"0")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("a",{parentName:"td",href:"https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch"},"NGC-PyTorch")),(0,r.kt)("td",{parentName:"tr",align:"center"},"1")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"left"},(0,r.kt)("a",{parentName:"td",href:"https://pytorch.org/cppdocs/installing.html"},"libtorch")),(0,r.kt)("td",{parentName:"tr",align:"center"},"1")))),(0,r.kt)("h3",{id:"compiling-with-integrated-third-party-libraries-using-ubuntu-opencv-as-an-example"},"Compiling with integrated third-party libraries (using Ubuntu-OpenCV as an example)"),(0,r.kt)("p",null,"By default, installing OpenCV using ",(0,r.kt)("inlineCode",{parentName:"p"},"apt-get install libopencv-dev")," satisfies ",(0,r.kt)("inlineCode",{parentName:"p"},"_GLIBCXX_USE_CXX11_ABI=1"),", which is not compatible with PyTorch from PyPI. However, you can compile PyTorch-compatible OpenCV by adding the ",(0,r.kt)("inlineCode",{parentName:"p"},"-D_GLIBCXX_USE_CXX11_ABI=0")," configuration to CMake."),(0,r.kt)("details",null,(0,r.kt)("summary",null,"Compilation Command"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"wget https://codeload.github.com/opencv/opencv/zip/refs/tags/4.5.4 -O opencv-4.5.4.zip\n\nunzip opencv-4.5.4.zip && pip3 install cmake\n\ncd opencv-4.5.4/ && \\\nsed -i '1a add_definitions(-D_GLIBCXX_USE_CXX11_ABI=0)' CMakeLists.txt  && \\\n      mkdir build && cd build && \\\n      cmake -D CMAKE_BUILD_TYPE=Release \\\n            -D BUILD_WITH_DEBUG_INFO=OFF \\\n            -D CMAKE_INSTALL_PREFIX=/usr/local/ \\\n            -D INSTALL_C_EXAMPLES=OFF \\\n            -D INSTALL_PYTHON_EXAMPLES=OFF \\\n            -DENABLE_NEON=OFF  \\\n            -D WITH_TBB=ON \\\n            -DBUILD_TBB=ON  \\\n            -DBUILD_WEBP=OFF \\\n            -D BUILD_ITT=OFF -D WITH_IPP=ON  \\\n            -D WITH_V4L=OFF \\\n            -D WITH_QT=OFF \\\n            -D WITH_OPENGL=OFF \\\n            -D BUILD_opencv_dnn=OFF \\\n            -DBUILD_opencv_java=OFF \\\n            -DBUILD_opencv_python2=OFF \\\n            -DBUILD_opencv_python3=ON \\\n            -D BUILD_NEW_PYTHON_SUPPORT=ON \\\n            -D BUILD_PYTHON_SUPPORT=ON \\\n            -D PYTHON_DEFAULT_EXECUTABLE=/usr/bin/python3 \\\n            -DBUILD_opencv_java_bindings_generator=OFF \\\n            -DBUILD_opencv_python_bindings_generator=ON \\\n            -D BUILD_EXAMPLES=OFF \\\n            -D WITH_OPENEXR=OFF \\\n            -DWITH_JPEG=ON  \\\n            -DBUILD_JPEG=ON\\\n            -D BUILD_JPEG_TURBO_DISABLE=OFF \\\n            -D BUILD_DOCS=OFF \\\n            -D BUILD_PERF_TESTS=OFF \\\n            -D BUILD_TESTS=OFF \\\n            -D BUILD_opencv_apps=OFF \\\n            -D BUILD_opencv_calib3d=OFF \\\n            -D BUILD_opencv_contrib=OFF \\\n            -D BUILD_opencv_features2d=OFF \\\n            -D BUILD_opencv_flann=OFF \\\n            -DBUILD_opencv_gapi=OFF \\\n            -D WITH_CUDA=OFF \\\n            -D WITH_CUDNN=OFF \\\n            -D OPENCV_DNN_CUDA=OFF \\\n            -D ENABLE_FAST_MATH=1 \\\n            -D WITH_CUBLAS=0 \\\n            -D BUILD_opencv_gpu=OFF \\\n            -D BUILD_opencv_ml=OFF \\\n            -D BUILD_opencv_nonfree=OFF \\\n            -D BUILD_opencv_objdetect=OFF \\\n            -D BUILD_opencv_photo=OFF \\\n            -D BUILD_opencv_stitching=OFF \\\n            -D BUILD_opencv_superres=OFF \\\n            -D BUILD_opencv_ts=OFF \\\n            -D BUILD_opencv_video=OFF \\\n            -D BUILD_videoio_plugins=OFF \\\n            -D BUILD_opencv_videostab=OFF \\\n            -DBUILD_EXAMPLES=OFF \\\n            -DBUILD_opencv_calib3d=OFF \\\n            -DBUILD_opencv_features2d=OFF\\\n            -DBUILD_opencv_flann=OFF\\\n            -DBUILD_opencv_ml=OFF\\\n            -DBUILD_opencv_videoio=OFF\\\n                .. && make -j4 && make install\n"))))}h.isMDXComponent=!0}}]);