---
id: introduction
title: 1. 介绍
type: explainer
---

torchpipe是为工业界和学术界所准备的一个图像音视频业务上线部署加速的工具集，torchpipe可以轻松集成到现有的线上服务的工作流程中，助力使用者能更加快速便捷部署包括但不限视觉、语音模型，一站式完成更多模型应用落地。

在实际业务应用中，通常需要将多个模型（包括其他计算节点或远程调用）的端到端业务逻辑部署在一起，以在线Serving的形式对外提供服务。为实现端到端深度学习系统的最佳性能和最佳体验的平衡，torchpipe框架支持：
- 单节点的多实例、动态批处理和动态尺度调整
- 多节点的流水线调度，
- 节点间的逻辑控制流
可当服务调用量增加时，整个业务方案通常面临着多节点交织时从算法侧提供解决方案。


![jpg](.././static/images/EngineFlow-light.png)
<center>torchpipe框架图</center> 

**torchpipe框架优势**：
 - 性能（吞吐量/延迟）上达到业务角度上的最优，减少广泛存在的负优化和节点间性能损耗。
 - 凭借细粒度泛型后端，便于硬件扩展，弱化硬件厂商生态迁移难度。
 - 简单而高性能的建模包括多模型融合在内的一些过于复杂的业务系统。工业界典型场景有智慧城市中多达10个模型节点的AI系统A、B，以及如果要极限优化，会涉及到子图独立调度、分桶调度、智能化组batch的OCR系统。
 - 最大限度摆脱 Python 运行时、GIL、异构硬件、虚拟化和多进程带来的性能损耗。

与许多其他服务化框架不同，我们将系统与 RPC 及负载均衡部分解耦，关注于 C++ 和 Python 接口的并发安全和流水线调度。
